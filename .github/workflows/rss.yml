name: Categorized RSS Alerts with Stock Recommendation

on:
  workflow_dispatch:

jobs:
  notify:
    runs-on: ubuntu-latest

    steps:
      - name: Set up environment
        run: |
          sudo apt-get update
          sudo apt-get install -y libxml2-utils w3m jq curl

      - name: Download previous hashes and last processed timestamp (if any)
        uses: actions/download-artifact@v4
        with:
          name: rss-cache
          path: .cache
        continue-on-error: true

      - name: Create cache file if not exists
        run: |
          mkdir -p .cache
          touch .cache/sent_hashes.txt
          touch .cache/last_processed_timestamp.txt

      - name: Parse RSS Feeds and Post to Slack
        run: |
          FEEDS=(
            "https://feed.businesswire.com/rss/home/?rss=G1QFDERJXkJeEFpRXEMGSQ5SVFJUGExaFEhaUlJDFUkQUhFUUFNdGEU="
            "https://www.globenewswire.com/rssfeed/exchange/Nasdaq,NYSE"
          )

          declare -A WEBHOOKS
          WEBHOOKS[general]="${{ secrets.SLACK_WEBHOOK_GENERAL }}"
          WEBHOOKS[medical]="${{ secrets.SLACK_WEBHOOK_MEDICAL }}"
          WEBHOOKS[contracts]="${{ secrets.SLACK_WEBHOOK_CONTRACTS }}"

          # Read the last processed timestamp
          LAST_PROCESSED_TIMESTAMP=$(cat .cache/last_processed_timestamp.txt || echo 0)

          for FEED_URL in "${FEEDS[@]}"; do
            echo "🔍 Checking Feed: $FEED_URL"
            XML=$(curl -s "$FEED_URL")

            for i in 1 2 3; do
              LINK=$(echo "$XML" | xmllint --xpath "string((//item|//entry)[$i]/link | (//item|//entry)[$i]/link/@href)" - 2>/dev/null)
              TITLE=$(echo "$XML" | xmllint --xpath "string((//item|//entry)[$i]/title)" - 2>/dev/null)
              DESCRIPTION=$(echo "$XML" | xmllint --xpath "string((//item|//entry)[$i]/description | //entry[$i]/summary)" - 2>/dev/null)
              PUBDATE=$(echo "$XML" | xmllint --xpath "string((//item|//entry)[$i]/pubDate | //entry[$i]/updated)" - 2>/dev/null)

              [ -z "$LINK" ] && continue
              [ -z "$TITLE" ] && TITLE="(No Title)"
              [ -z "$DESCRIPTION" ] && DESCRIPTION="(No summary available)"
              [ -z "$PUBDATE" ] && PUBDATE="(No date provided)"

              DESCRIPTION=$(echo "$DESCRIPTION" | w3m -dump -T text/html | head -c 300)
              CONTENT="$TITLE $DESCRIPTION"
              CONTENT_LOWER=$(echo "$CONTENT" | tr '[:upper:]' '[:lower:]')

              # Get the timestamp of the article's pubDate and convert to Unix timestamp
              ARTICLE_TIME=$(date -d "$PUBDATE" +%s)

              # Skip the article if it's older than the last processed timestamp
              if [ $ARTICLE_TIME -le $LAST_PROCESSED_TIMESTAMP ]; then
                echo "Skipping article: $TITLE (already processed)"
                continue
              fi

              # Process the article as it is newer
              HEADLINE_HASH=$(echo "$TITLE" | md5sum | cut -d ' ' -f 1)
              if grep -q "$HEADLINE_HASH" .cache/sent_hashes.txt; then
                echo "Skipping duplicate article: $TITLE"
                continue
              fi

              echo "$HEADLINE_HASH" >> .cache/sent_hashes.txt

              # Use Hugging Face API to analyze sentiment (or any sentiment API)
              RESPONSE=$(curl -s -X POST https://api-inference.huggingface.co/models/distilbert-base-uncased-finetuned-sst-2-english \
                -H "Authorization: Bearer ${{ secrets.HUGGINGFACE_API_KEY }}" \
                -d '{"inputs": "'"$TITLE $DESCRIPTION"'"}')

              SENTIMENT=$(echo "$RESPONSE" | jq -r '.[0].label')

              # Determine Buy/Sell based on sentiment
              if [[ "$SENTIMENT" == "POSITIVE" ]]; then
                RECOMMENDATION="BUY"
              elif [[ "$SENTIMENT" == "NEGATIVE" ]]; then
                RECOMMENDATION="SELL"
              else
                RECOMMENDATION="HOLD"
              fi

              # 🧱 Format Slack message with real line breaks
              TEXT=$(printf ":bell: *New Article:*\n%s *%s*\n:page_facing_up: %s\n:link: <%s|Read more>\n:clock3: *Posted:* %s\n:information_source: Recommendation: %s\n───────────────" \
                "$SENTIMENT" "$TITLE" "$DESCRIPTION" "$LINK" "$PUBDATE" "$RECOMMENDATION")

              PAYLOAD=$(jq -n --arg text "$TEXT" \
                '{blocks: [ { type: "section", text: { type: "mrkdwn", text: $text } } ]}')

              echo "📤 Sending to Slack ($CATEGORY)..."
              curl -X POST "${WEBHOOKS[$CATEGORY]}" \
                -H 'Content-type: application/json' \
                --data "$PAYLOAD"

              # Update the last processed timestamp (most recent article's timestamp)
              echo $ARTICLE_TIME > .cache/last_processed_timestamp.txt
            done
          done

      - name: Upload updated hashes
        uses: actions/upload-artifact@v4
        with:
          name: rss-cache
          path: .cache/sent_hashes.txt

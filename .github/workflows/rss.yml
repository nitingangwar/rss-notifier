name: Categorized RSS Alerts with Sentiment

on:
  workflow_dispatch: {}
  # schedule:
  #   - cron: "*/10 * * * *"

concurrency:
  group: rss-alerts
  cancel-in-progress: false

jobs:
  notify:
    runs-on: ubuntu-latest

    steps:
      - name: Set up environment
        run: |
          sudo apt-get update
          sudo apt-get install -y libxml2-utils w3m jq curl coreutils

      # Cross-run cache for dedupe + inventory
      - name: Restore cache
        uses: actions/cache@v4
        with:
          path: .cache
          key: rss-cache-${{ runner.os }}-${{ github.run_id }}
          restore-keys: |
            rss-cache-${{ runner.os }}-

      - name: Create cache files if not exists
        run: |
          mkdir -p .cache
          [ -f .cache/sent_hashes.txt ] || touch .cache/sent_hashes.txt
          [ -f .cache/last_10min_articles.txt ] || touch .cache/last_10min_articles.txt
          [ -f .cache/company_index.json ] || echo '{}' > .cache/company_index.json

      - name: Sanity-check Yahoo endpoints (logs only)
        run: |
          UA='Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36'
          echo "autoc (Apple):"
          curl -sSL --max-time 8 -H "User-Agent: $UA" \
            "https://autoc.finance.yahoo.com/autoc?query=Apple&region=US&lang=en-US" | head -c 300; echo
          echo "search (Apple):"
          curl -sSL --max-time 8 -H "User-Agent: $UA" \
            "https://query1.finance.yahoo.com/v1/finance/search?q=Apple&quotesCount=2&newsCount=0" | head -c 300; echo

      - name: Parse RSS Feeds, filter PRN via Yahoo, and Post to Slack
        env:
          SLACK_WEBHOOK_GENERAL: ${{ secrets.SLACK_WEBHOOK_GENERAL }}
          SLACK_WEBHOOK_MEDICAL: ${{ secrets.SLACK_WEBHOOK_MEDICAL }}
          SLACK_WEBHOOK_CONTRACTS: ${{ secrets.SLACK_WEBHOOK_CONTRACTS }}
        run: |
          set -euo pipefail

          # ---------- Safe helpers (no brittle pipes) ----------
          safe_json_has_quotes() { jq -e '.quotes | length >= 1' <<<"$1" >/dev/null 2>&1; }
          safe_json_is_valid()   { jq -e . <<<"$1" >/dev/null 2>&1; }
          safe_xpath() { xmllint --xpath "string($2)" "$1" 2>/dev/null || true; }

          FEEDS=(
            "https://feed.businesswire.com/rss/home/?rss=G1QFDERJXkJeEFpRXEMGSQ5SVFJUGExaFEhaUlJDFUkQUhFUUFNdGEU="
            "https://www.globenewswire.com/rssfeed/exchange/Nasdaq,NYSE"
            "https://www.prnewswire.com/rss/all-news-releases-from-PR-newswire-news.rss"
          )
          PRN_FEED="https://www.prnewswire.com/rss/all-news-releases-from-PR-newswire-news.rss"

          declare -A WEBHOOKS=(
            [general]="${SLACK_WEBHOOK_GENERAL}"
            [medical]="${SLACK_WEBHOOK_MEDICAL}"
            [contracts]="${SLACK_WEBHOOK_CONTRACTS}"
          )

          PER_FEED_ITEMS=3
          WINDOW_SEC=600
          NEG_TTL_DAYS=30
          NEG_TTL_SEC=$((NEG_TTL_DAYS * 24 * 3600))

          # Yahoo headers
          YF_UA='Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36'
          YF_LANG='en-US,en;q=0.9'

          CURRENT_TIME=$(date -u +%s)
          TEN_MINUTES_AGO=$((CURRENT_TIME - WINDOW_SEC))

          # Prune rolling 10-min headline cache (format: "<epoch> <headline_hash>")
          awk -v cutoff="$TEN_MINUTES_AGO" '{
            if (NF >= 2) { epoch=$1; if (epoch ~ /^[0-9]+$/ && epoch >= cutoff) print $0; }
          }' .cache/last_10min_articles.txt > .cache/_pruned.tmp || true
          mv .cache/_pruned.tmp .cache/last_10min_articles.txt

          # ---------- Extractor helpers ----------
          norm_company_name() {
            echo "$1" \
              | sed 's/[‚Ñ¢¬Æ¬©]//g' \
              | sed 's/[‚Äú‚Äù"'\''()]//g' \
              | sed 's/&/ and /g' \
              | sed -E 's/\b(Inc|Incorporated|Corp|Corporation|Co|Company|Ltd|Limited|PLC|Group|Holdings?|LLC|LP|AG|S\.?A\.?)\b\.?,?//Ig' \
              | sed -E 's/ +/ /g; s/^ +| +$//g' \
              | tr '[:upper:]' '[:lower:]'
          }

          extract_candidates() {
            # prints 1 or 2 lines: primary company, and optional secondary (for "X and Y Announce ‚Ä¶")
            local title="$1"

            local pre; pre=$(echo "$title" | sed -E 's/ ‚Äî / - /g' | awk -F' - |:|\\|\\|' '{print $1}')
            [ -z "$pre" ] && pre="$title"
            pre=$(echo "$pre" | sed 's/[‚Äú‚Äù"()‚Ñ¢¬Æ¬©]//g' | tr -s ' ')

            local first; first=$(awk '{print $1}' <<<"$pre")
            if echo "$first" | grep -qE '^[A-Z0-9\-]{2,}$'; then
              echo "$first"
              return 0
            fi

            VERBS='announces|announce|launches|launch|reports|report|unveils|introduces|reveals|confirms|completes|signs|wins|awarded|enters|partners|acquires|files|prices|lists|successfully|passes|secures|appoints|names|extends|expands|approves|approved'
            GENERIC='inverters|series|platform|solution|solutions|product|products|system|systems|software|hardware|services|technology|technologies|network|appliance|appliances|device|devices|trial|results'

            awk -v verbs="$VERBS" -v gener="$GENERIC" '
              function tolow(s){ out=s; gsub(/[[:punct:]]/,"",out); return tolower(out) }
              BEGIN{ split(verbs,v,"|"); for(i in v) V[v[i]]=1;
                     split(gener,g,"|"); for(i in g) G[g[i]]=1; }
              {
                n=NF; primary=""; secondary=""; seen_and=0;
                for(i=1;i<=n;i++){
                  wl=tolow($i)
                  if (wl in V) break
                  if (wl=="and"){
                    if (length(primary)>0){ seen_and=1; next }
                  }
                  is_caps=($i ~ /^[A-Z][A-Za-z0-9.-]*$/ || $i ~ /^[A-Z0-9-]{2,}$/)
                  if (is_caps){
                    if (seen_and==0){
                      primary = (length(primary)? primary" ":"") $i
                    } else {
                      secondary = (length(secondary)? secondary" ":"") $i
                    }
                  } else {
                    if (length(primary)>0 && seen_and==0) { break }
                    if (length(secondary)>0 && seen_and==1) { break }
                  }
                }
                split(primary, p, " ")
                if (length(p)>1 && (tolow(p[length(p)]) in G)) { p[length(p)]=""; primary=""; for(k in p) if(p[k]!="") primary=(length(primary)?primary" ":"") p[k] }
                print primary
                if (length(secondary)>0) print secondary
              }' <<<"$pre"
          }

          # ---------- Yahoo resolver (AUTOC first, then search) ----------
          lookup_company_exchange() {
            local raw="$1"
            local key norm entry cached_ticker last_checked last_epoch age
            norm=$(norm_company_name "$raw")
            key="$norm"

            local now_epoch
            now_epoch=$(date -u +%s)

            # 1) Inventory check (with TTL for negative)
            if jq -e --arg k "$key" 'has($k)' .cache/company_index.json >/dev/null; then
              entry=$(jq -r --arg k "$key" '.[$k]' .cache/company_index.json)
              cached_ticker=$(jq -r '.ticker' <<<"$entry")
              last_checked=$(jq -r '.last_checked' <<<"$entry")
              last_epoch=$(date -u -d "$last_checked" +%s 2>/dev/null || echo 0)
              if [ "$cached_ticker" != "null" ] && [ -n "$cached_ticker" ]; then
                echo "$entry"; return 0
              fi
              age=$(( now_epoch - last_epoch ))
              if [ "$last_epoch" -gt 0 ] && [ "$age" -lt "$NEG_TTL_SEC" ]; then
                echo "$entry"; return 0
              fi
            fi

            # 2) Yahoo AUTOC (more reliable)
            local q j ok symbol exchDisp
            q=$(printf '%s' "$raw" | sed 's/ /%20/g')
            ok=false; symbol=""; exchDisp=""; j=""

            j=$(curl -sSL --max-time 8 \
                  -H "User-Agent: $YF_UA" -H "Accept-Language: $YF_LANG" \
                  "https://autoc.finance.yahoo.com/autoc?query=$q&region=US&lang=en-US" || true)
            safe_json_is_valid "$j" || j=""

            if [ -n "$j" ]; then
              lines_json=$(jq -cr '.ResultSet.Result[]? | select(.type=="S") | {symbol,exchDisp}' <<<"$j" 2>/dev/null || true)
              while IFS= read -r line; do
                [ -z "$line" ] && continue
                symbol=$(jq -r '.symbol' <<<"$line")
                exchDisp=$(jq -r '.exchDisp' <<<"$line")
                if echo "$exchDisp" | grep -Ei '^(NASDAQ|NYSE|NYSE American|NYSE Arca)$' >/dev/null; then
                  ok=true; break
                fi
              done <<<"$lines_json"
            fi

            # 3) Fallback to old search if AUTOC failed
            if [ "$ok" != true ]; then
              j=$(curl -sSL --max-time 8 \
                    -H "User-Agent: $YF_UA" -H "Accept-Language: $YF_LANG" \
                    "https://query1.finance.yahoo.com/v1/finance/search?q=$q&quotesCount=5&newsCount=0" || true)
              safe_json_is_valid "$j" || j=""
              if [ -n "$j" ]; then
                lines_json=$(jq -cr '.quotes[]? | select(.quoteType=="EQUITY") | {symbol:.symbol,exchDisp:.exchDisp}' <<<"$j" 2>/dev/null || true)
                while IFS= read -r line; do
                  [ -z "$line" ] && continue
                  symbol=$(jq -r '.symbol' <<<"$line")
                  exchDisp=$(jq -r '.exchDisp' <<<"$line")
                  if echo "$exchDisp" | grep -Ei '^(NASDAQ|NYSE|NYSE American|NYSE Arca)$' >/dev/null; then
                    ok=true; break
                  fi
                done <<<"$lines_json"
              fi
            fi

            # 4) Write result (positive or negative) to inventory
            if [ "$ok" = true ]; then
              tmp=$(mktemp)
              jq --arg k "$key" --arg sym "$symbol" --arg exd "$exchDisp" --arg t "$(date -u +%FT%TZ)" \
                 '.[$k] = {ticker:$sym, exchange:$exd, last_checked:$t}' \
                 .cache/company_index.json > "$tmp" && mv "$tmp" .cache/company_index.json
              echo "{\"ticker\":\"$symbol\",\"exchange\":\"$exchDisp\"}"
            else
              tmp=$(mktemp)
              jq --arg k "$key" --arg t "$(date -u +%FT%TZ)" \
                 '.[$k] = {ticker:null, exchange:null, last_checked:$t}' \
                 .cache/company_index.json > "$tmp" && mv "$tmp" .cache/company_index.json
              echo '{"ticker":null,"exchange":null}'
            fi
            return 0
          }

          NEW_ARTICLE_FOUND=false

          for FEED_URL in "${FEEDS[@]}"; do
            echo "üîç Checking Feed: $FEED_URL"

            XML_FILE=$(mktemp)
            curl -sL "$FEED_URL" > "$XML_FILE" || true
            if [ ! -s "$XML_FILE" ]; then
              echo "‚ö†Ô∏è  Empty response from feed."
              rm -f "$XML_FILE"
              continue
            fi

            for i in $(seq 1 "$PER_FEED_ITEMS"); do
              LINK=$(safe_xpath "$XML_FILE" "(//item|//entry)[$i]/link | (//item|//entry)[$i]/link/@href")
              TITLE=$(safe_xpath "$XML_FILE" "(//item|//entry)[$i]/title")
              DESCRIPTION=$(safe_xpath "$XML_FILE" "(//item|//entry)[$i]/description | //entry[$i]/summary")
              PUBDATE=$(safe_xpath "$XML_FILE" "(//item|//entry)[$i]/pubDate | //entry[$i]/updated")

              [ -z "$LINK" ] && continue
              [ -z "$TITLE" ] && TITLE="(No Title)"
              [ -z "$DESCRIPTION" ] && DESCRIPTION="(No summary available)"
              [ -z "$PUBDATE" ] && PUBDATE=""

              DESCRIPTION=$(echo "$DESCRIPTION" | w3m -dump -T text/html | tr -s '[:space:]' ' ' | sed 's/^ *//;s/ *$//' | head -c 300)
              CONTENT="$TITLE $DESCRIPTION"
              CONTENT_LOWER=$(echo "$CONTENT" | tr '[:upper:]' '[:lower:]')

              ARTICLE_TIME=$(date -d "$PUBDATE" +%s 2>/dev/null || echo 0)
              if [ "$ARTICLE_TIME" -eq 0 ] || [ "$ARTICLE_TIME" -lt "$TEN_MINUTES_AGO" ]; then
                echo "‚è±Ô∏è Skipping (invalid/old date): $TITLE"
                continue
              fi

              HEADLINE_HASH=$(echo -n "$TITLE" | md5sum | cut -d ' ' -f1)
              if grep -qx "$HEADLINE_HASH" <(awk '{print $2}' .cache/last_10min_articles.txt); then
                echo "üîÅ Skipping duplicate headline (10-min window): $TITLE"
                continue
              fi

              LINK_HASH=$(echo -n "$LINK" | md5sum | cut -d ' ' -f1)
              if grep -qx "$LINK_HASH" .cache/sent_hashes.txt; then
                echo "üß≠ Already sent (by link): $TITLE"
                continue
              fi
              if grep -qx "$HEADLINE_HASH" .cache/sent_hashes.txt; then
                echo "üß≠ Already sent (by headline): $TITLE"
                continue
              fi

              # --- US-listing filter for PR Newswire ONLY (via inventory+lookup)
              if [ "$FEED_URL" = "$PRN_FEED" ]; then
                # Extract one or two candidate company names
                mapfile -t CANDS < <(extract_candidates "$TITLE" | sed -E 's/^ +| +$//g' | sed '/^$/d')
                PRN_US_OK=false
                PRN_EXCH=""
                PRN_TICKER=""
                for cand in "${CANDS[@]:-}"; do
                  info_json=$(lookup_company_exchange "$cand")
                  exch=$(jq -r '.exchange // empty' <<<"$info_json")
                  ticker=$(jq -r '.ticker // empty' <<<"$info_json")
                  if echo "$exch" | grep -Ei '^(NASDAQ|NYSE|NYSE American|NYSE Arca)$' >/dev/null; then
                    PRN_US_OK=true
                    PRN_EXCH="$exch"
                    PRN_TICKER="$ticker"
                    break
                  fi
                done

                if [ "$PRN_US_OK" != true ]; then
                  echo "üá∫üá∏‚õî Skipping PRN item not resolved to US exchange: $TITLE (candidates tried: ${CANDS[*]:-none})"
                  continue
                fi
                echo "üá∫üá∏‚úÖ PRN item resolved to US exchange: $TITLE (ticker: ${PRN_TICKER:-N/A}, exchange: $PRN_EXCH)"
              fi

              # Categorize
              if echo "$CONTENT_LOWER" | grep -qE "positive topline|positive trial results|collaboration|funding"; then
                CATEGORY="medical"
              elif echo "$CONTENT_LOWER" | grep -qE "contract awarded|acquisition|investment|deal|strategic partnership"; then
                CATEGORY="contracts"
              else
                CATEGORY="general"
              fi

              # Sentiment + naive recommendation
              if echo "$CONTENT_LOWER" | grep -qE "record|growth|surge|positive|expands|secured|approved|funding|investment|invests|acquire|acquired|launch|topline|announces|partnership"; then
                SENTIMENT=":large_green_circle: [POSITIVE]"
                RECOMMENDATION="BUY"
              elif echo "$CONTENT_LOWER" | grep -qE "layoff|lawsuit|delay|loss|drop|decline|recall|fails|resigns|investigation"; then
                SENTIMENT=":red_circle: [NEGATIVE]"
                RECOMMENDATION="SELL"
              else
                SENTIMENT=":white_circle: [NEUTRAL]"
                RECOMMENDATION="HOLD"
              fi

              PAYLOAD=$(jq -n \
                --arg title "$TITLE" \
                --arg desc "$DESCRIPTION" \
                --arg link "$LINK" \
                --arg sentiment "$SENTIMENT" \
                --arg pubdate "${PUBDATE:-Unknown}" \
                --arg rec "$RECOMMENDATION" \
                '{
                  blocks: [
                    { "type": "section", "text": { "type": "mrkdwn", "text": ":bell: *New Article*\n\($sentiment) *\($title)*" } },
                    { "type": "section", "text": { "type": "mrkdwn", "text": ":page_facing_up: \($desc)" } },
                    { "type": "context", "elements": [
                        { "type": "mrkdwn", "text": ":link: <\($link)|Read more>" },
                        { "type": "mrkdwn", "text": ":clock3: Posted: \($pubdate)" },
                        { "type": "mrkdwn", "text": ":mag: Suggestion: *\($rec)*" }
                      ]
                    }
                  ]
                }')

              echo "üì§ Sending to Slack ($CATEGORY)‚Ä¶"
              curl -s -X POST "${WEBHOOKS[$CATEGORY]}" \
                -H 'Content-type: application/json' \
                --data "$PAYLOAD" >/dev/null || true

              echo "$LINK_HASH" >> .cache/sent_hashes.txt
              echo "$HEADLINE_HASH" >> .cache/sent_hashes.txt
              echo "$CURRENT_TIME $HEADLINE_HASH" >> .cache/last_10min_articles.txt

              NEW_ARTICLE_FOUND=true
            done

            rm -f "$XML_FILE"
          done

          if [ "$NEW_ARTICLE_FOUND" = false ]; then
            echo "‚úÖ No new articles in the last 10 minutes."
          fi

      # ===== Manual PRN-style headlines test (extractor + Yahoo AUTOC) =====
      - name: Manual headline extractor + Yahoo lookup test (improved)
        run: |
          set -euo pipefail

          YF_UA='Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36'
          YF_LANG='en-US,en;q=0.9'
          safe_json_is_valid()   { jq -e . <<<"$1" >/dev/null 2>&1; }

          extract_candidates() { # same as above (minimal inline)
            local title="$1"
            local pre; pre=$(echo "$title" | sed -E 's/ ‚Äî / - /g' | awk -F' - |:|\\|\\|' '{print $1}')
            [ -z "$pre" ] && pre="$title"
            pre=$(echo "$pre" | sed 's/[‚Äú‚Äù"()‚Ñ¢¬Æ¬©]//g' | tr -s ' ')
            local first; first=$(awk '{print $1}' <<<"$pre")
            if echo "$first" | grep -qE '^[A-Z0-9\-]{2,}$'; then echo "$first"; return; fi
            VERBS='announces|announce|launches|launch|reports|report|unveils|introduces|reveals|confirms|completes|signs|wins|awarded|enters|partners|acquires|files|prices|lists|successfully|passes|secures|appoints|names|extends|expands|approves|approved'
            awk -v verbs="$VERBS" 'function tolow(s){ out=s; gsub(/[[:punct:]]/,"",out); return tolower(out) }
              BEGIN{ split(verbs,v,"|"); for(i in v) V[v[i]]=1; }
              { n=NF; chunk="";
                for(i=1;i<=n;i++){ wl=tolow($i); if (wl in V) break; if ($i ~ /^[A-Z][A-Za-z0-9.-]*$/ || $i ~ /^[A-Z0-9-]{2,}$/){ chunk = (length(chunk)?chunk" ":"") $i } else if (length(chunk)>0) break }
                print chunk }' <<<"$pre"
          }

          lookup_autoc() {
            local raw="$1"
            local q=$(printf '%s' "$raw" | sed 's/ /%20/g')
            echo "üîé Lookup: $raw"
            j=$(curl -sSL --max-time 8 -H "User-Agent: $YF_UA" -H "Accept-Language: $YF_LANG" \
                "https://autoc.finance.yahoo.com/autoc?query=$q&region=US&lang=en-US" || true)
            safe_json_is_valid "$j" || j=""
            if [ -n "$j" ]; then
              hits=$(jq -cr '[.ResultSet.Result[]? | select(.type=="S")][0:5]' <<<"$j" 2>/dev/null || echo "[]")
              if [ "$hits" != "[]" ]; then
                echo "$hits" | jq -cr '.[] | "\(.symbol) / \(.exchDisp) ‚Äî \(.name // .symbol)"'
              else
                echo "‚ùå No match"
              fi
            else
              echo "‚ùå No match"
            fi
            echo "---------------------------------"
          }

          echo "üì∞ Testing improved extractor + Yahoo AUTOC on PRN-style headlines‚Ä¶"
          HEADLINES=(
            "AEWIN Launches SCB-1953 Series High-Performance Network Appliances Powered by Intel Xeon 6 Processors"
            "Sungrow Inverters Successfully Pass the Brazilian Grid Operator Validations"
            "Apple Announces New AI-Powered iPhone Features"
            "Tesla Signs Strategic Partnership to Expand EV Charging Network"
            "Novartis Reports Positive Topline Results from Phase 3 Trial"
            "Infosys Partners with US Bank for Cloud Modernization"
            "Zoom Video Communications Unveils Next-Gen Collaboration Platform"
            "Pfizer and BioNTech Announce FDA Approval of Updated COVID-19 Vaccine"
          )

          for H in "${HEADLINES[@]}"; do
            echo "üì∞ $H"
            cand=$(extract_candidates "$H" | sed -E 's/^ +| +$//g' | head -n1)
            if [ -z "$cand" ]; then
              echo "   ‚Üí (no candidate extracted)"; echo "---------------------------------"; continue
            fi
            echo "   ‚Üí Candidate: $cand"
            lookup_autoc "$cand"
          done

      # ===== Inventory inspection & publishing =====
      - name: Inspect company inventory (summary)
        run: |
          if [ ! -f .cache/company_index.json ]; then
            echo "No inventory file yet."; exit 0;
          fi

          echo "üì¶ company_index.json"
          ls -lh .cache/company_index.json

          echo "Total entries:"
          jq 'keys | length' .cache/company_index.json

          echo "Positive entries (have ticker/exchange):"
          jq '[ to_entries[] | select(.value.ticker != null and .value.exchange != null) ] | length' .cache/company_index.json

          echo "Negative entries (null ticker/exchange):"
          jq '[ to_entries[] | select(.value.ticker == null or .value.exchange == null) ] | length' .cache/company_index.json

          echo "Sample positives (first 10):"
          jq -r '[ to_entries[] | select(.value.ticker != null) ][0:10]' .cache/company_index.json

      - name: Inventory summary (Job Summary)
        run: |
          if [ ! -f .cache/company_index.json ]; then
            echo "No inventory yet" >> "$GITHUB_STEP_SUMMARY"; exit 0;
          fi
          POS=$(jq '[ to_entries[] | select(.value.ticker != null and .value.exchange != null) ] | length' .cache/company_index.json)
          NEG=$(jq '[ to_entries[] | select(.value.ticker == null or .value.exchange == null) ] | length' .cache/company_index.json)
          {
            echo "### Company Inventory Summary"
            echo ""
            echo "| Metric | Count |"
            echo "|---|---:|"
            echo "| Positives (ticker found) | $POS |"
            echo "| Negatives (no match) | $NEG |"
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Publish company inventory (artifact)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: company-index
          path: .cache/company_index.json
